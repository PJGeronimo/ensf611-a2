{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Paolo Geronimo (30086289)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yellowbrick.datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33583c67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: 262200\n",
      "Shape of X: (4600, 57)\n",
      "Type of X:\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "Size of y: 4600\n",
      "Shape of y: (4600,)\n",
      "Type of y:\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "X, y = yellowbrick.datasets.loaders.load_spam()\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "print (f\"Size of X: {X.size}\")\n",
    "print (f\"Shape of X: {X.shape}\")\n",
    "print (\"Type of X:\")\n",
    "print (X.dtypes)\n",
    "\n",
    "print (f\"Size of y: {y.size}\")\n",
    "print (f\"Shape of y: {y.shape}\")\n",
    "print (\"Type of y:\")\n",
    "print (y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7204f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc4a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small\n",
    "\n",
    "X_small, X1, y_small, y1 = train_test_split(X, y, train_size = 0.05, random_state = 0)\n",
    "#X1 and y1 are not needed because we only want to extract 5% of the data, which are appended to X_small and y_small\n",
    "\n",
    "X_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4b5c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Data</th>\n",
       "      <td>(4600, 57)</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.937391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two Columns</th>\n",
       "      <td>(4600, 2)</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Small Data</th>\n",
       "      <td>(230, 57)</td>\n",
       "      <td>0.936047</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Size Training Accuracy Validation Accuracy\n",
       "Full Data    (4600, 57)          0.928406            0.937391\n",
       "Two Columns   (4600, 2)          0.608406            0.613043\n",
       "Small Data    (230, 57)          0.936047            0.931034"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# instantiate model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "# in order to loop through the 3 different datasets, create a list of lists\n",
    "# where each list is the X and Y DataFrames to be processed\n",
    "# datasets[0] is the full dataset\n",
    "# datasets[1] is the first 2 columns of X and Y\n",
    "# datasets[2] is X_small and Y_small\n",
    "datasets = [[X, y], [X.iloc[:, :2], y], [X_small, y_small]]\n",
    "\n",
    "results = pd.DataFrame(index = [\"Full Data\" , \"Two Columns\", \"Small Data\"], columns = [\"Size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "for index in range(len(datasets)):\n",
    "    current_dataset = datasets[index] # set current dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(current_dataset[0], current_dataset[1], random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    results.iloc[index, 0] = current_dataset[0].shape\n",
    "    results.iloc[index, 1] = model.score(X_train, y_train) # training accuracy\n",
    "    results.iloc[index, 2] = model.score(X_test, y_test) # validation accuracy\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The validation accuracy increases as the size of the training set increases. When the full dataset is used to create the split, we get a validation accuracy of 0.937. When we have the same number of data points, but only 2 features, we get a validation accuracy of 0.613. Finally, when we use all features but only 5% of the dataset to create the split, we get a validation accuracy of 0.931.\n",
    "\n",
    "2. A false positive would be an email marked as spam when it's not. A false negative would be a spam email not marked as spam. I think the first case, where a real email is marked as spam, is worse. This is because we don't typically go through our spam folders, so the real email isn't likely to be opened. A spam email marked as real isn't as bad because the user could potentially recognize it as spam upon reading it, then mark the email as spam or even block the sender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from the examples found on D2L. In particular, ML_ex_solution.ipynb.\n",
    "2. I completed the steps in chronological order.\n",
    "3. I did not use generative AI.\n",
    "4. My biggest challenge came from using the test_train_split function. At first I didn't quite understand how it worked. I had a bit of trouble understanding what exactly it returned, and which hyperparameters to use. To get a better grasp of the function, I went over the documentation on the scikit website: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html. Another challenge I faced was creating the loop to generate the results. At first, I tried iterating through the objects themselves, but that was unsuccessful. The current implementation iterates through integers, which seems to work better when getting specific indexes in the list of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (1030, 8)\n",
      "Types in X: cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "Size of y: (1030,)\n",
      "Types in y: float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "X, y = yellowbrick.datasets.loaders.load_concrete()\n",
    "\n",
    "print(f\"Size of X: {X.shape}\")\n",
    "print(f\"Types in X: {X.dtypes}\")\n",
    "print(f\"Size of y: {y.shape}\")\n",
    "print(f\"Types in y: {y.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# training accuracy\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# validation accuracy\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Training Accuracy Validation Accuracy\n",
       "MSE             111.358439           95.904136\n",
       "R2 Score          0.610823            0.623414"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(index = [\"MSE\", \"R2 Score\"], columns = [\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "results.loc[\"MSE\"][\"Training Accuracy\"] = train_mse\n",
    "results.loc[\"MSE\"][\"Validation Accuracy\"] = test_mse\n",
    "results.loc[\"R2 Score\"][\"Training Accuracy\"] = train_r2\n",
    "results.loc[\"R2 Score\"][\"Validation Accuracy\"] = test_r2\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ff4e2-002e-4c67-a066-0b88e3f64445",
   "metadata": {},
   "source": [
    "Since an R2 score of 1 means a perfect model, an R2 score of ~0.6 shown above is a moderately good model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from the examples and lab notebooks on D2L. In particular, ML_ex.ipynb and Linear_Regression_Lab_2.ipynb.\n",
    "2. I completed the steps in chronological order.\n",
    "3. I did not use generative AI.\n",
    "4. The challenge I faced in this section was step 4. I originally misinterpreted the problem statement, and thought that mean squared error and R2 score should have been used in some sort of formula to calculate training and validation accuracy. I realized that it meant to use the training/test data to make predictions, then use that to calculate MSE and R2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "The most obvious pattern I found was in the results in Part 1. The most complete dataset is the one that had the best results, which is pretty self-explanatory. However, I found it interesting that the dataset with 2 columns performed significantly worse than the small dataset. The 2 column dataset had a training accuracy of ~0.608, while the small dataset had a training accuracy of ~0.936.  This demonstrates that removing features has a much more significant impact than removing samples.\n",
    "\n",
    "In Part 2, I noticed that the validation accuracy results were slightly better than the training accuracy results. This is interesting to me because I would have guessed that the training accuracy results would be better, since that data was used to train the model in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "What I liked about this assignment is there is a clear path to get the results, similar to the ML workflow example. Each step in the workflow is distinct and it's not really possible to do them in the wrong order, making it easy to get the hang of. My biggest challenge was learning how to use the train_test_split() method, which I described in the Part 1 Process Description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47623d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_results = pd.DataFrame(index = [\"MSE\", \"R2 Score\"], columns = [\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "ridge_model = Ridge(alpha = 100).fit(X_train, y_train)\n",
    "\n",
    "# training accuracy\n",
    "ridge_train_pred = ridge_model.predict(X_train) \n",
    "ridge_results.loc[\"MSE\"][\"Training Accuracy\"] = mean_squared_error(y_train, ridge_train_pred)\n",
    "ridge_results.loc[\"R2 Score\"][\"Training Accuracy\"] = r2_score(y_train, ridge_train_pred)\n",
    "\n",
    "# validation accuracy\n",
    "ridge_test_pred = ridge_model.predict(X_test) \n",
    "ridge_results.loc[\"MSE\"][\"Validation Accuracy\"] = mean_squared_error(y_test, ridge_test_pred)\n",
    "ridge_results.loc[\"R2 Score\"][\"Validation Accuracy\"] = r2_score(y_test, ridge_test_pred)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_results = pd.DataFrame(index = [\"MSE\", \"R2 Score\"], columns = [\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "lasso_model = Lasso(alpha = 0.1).fit(X_train, y_train)\n",
    "\n",
    "# training accuracy\n",
    "lasso_train_pred = lasso_model.predict(X_train)\n",
    "lasso_results.loc[\"MSE\"][\"Training Accuracy\"] = mean_squared_error(y_train, lasso_train_pred)\n",
    "lasso_results.loc[\"R2 Score\"][\"Training Accuracy\"] = r2_score(y_train, lasso_train_pred)\n",
    "\n",
    "# validation accuracy\n",
    "lasso_test_pred = lasso_model.predict(X_test)\n",
    "lasso_results.loc[\"MSE\"][\"Validation Accuracy\"] = mean_squared_error(y_test, lasso_test_pred)\n",
    "lasso_results.loc[\"R2 Score\"][\"Validation Accuracy\"] = r2_score(y_test, lasso_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1db7c9-30c1-48a7-81f3-ec613f90d51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear results\n",
      "          Training Accuracy Validation Accuracy\n",
      "MSE             111.358439           95.904136\n",
      "R2 Score          0.610823            0.623414 \n",
      "\n",
      "Ridge results\n",
      "          Training Accuracy Validation Accuracy\n",
      "MSE             111.358548           95.894268\n",
      "R2 Score          0.610823            0.623453 \n",
      "\n",
      "Lasso results\n",
      "          Training Accuracy Validation Accuracy\n",
      "MSE             111.359051           95.866646\n",
      "R2 Score          0.610821            0.623562 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear results\\n\", results, \"\\n\")\n",
    "print(\"Ridge results\\n\", ridge_results,\"\\n\" )\n",
    "print(\"Lasso results\\n\", lasso_results, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "After some trial and error with different alpha values, the best value for the Ridge model was 100. When trying different values, the Training R2 score remained the same as the Linear model, while the Validation R2 score saw small improvements as alpha increased.\n",
    "\n",
    "For the Lasso model, alpha = 0.1 provided the best balance in terms of how the Training R2 score and Validation R2 score were affected. When using alpha = 0.01, the Training R2 score is the same as the Linear model, while the Validation R2 score improves very slightly. However, when using 0.1, the Training R2 score goes down almost insigificantly, while the R2 score sees a bigger improvement. This trend continues as alpha increases.\n",
    "\n",
    "As shown in the three tables above, the R2 scores better, but not significantly different than the Linear model. Since the R2 Scores didn't change much, these models are also moderately good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bb1a2-1e3f-4f92-af02-ca7985f5ce6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
